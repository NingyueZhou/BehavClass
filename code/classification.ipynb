{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4941c89",
   "metadata": {},
   "source": [
    "# Behavior Classification using Explainable Active Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23534a3",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "DLC_DATASET_PATH = os.getenv('DLC_DATASET_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af404fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_RATE = 30\n",
    "SAMPLE_RATE = 10\n",
    "MULTI_ANIMAL = False\n",
    "LIKELIHOOD_THRESHOLD = 0.6\n",
    "BODY_PARTS = [\"tailbase\", \"earR\", \"earL\", \"msBase\", \"msTop\", \"centroid\", \"cleft\", \"cright\"]\n",
    "RULE_BASED_LABELS = [\"shuttles_label_naive1\", \"shuttles_label_naive2\", \"shuttles_label_naive3\", \"shuttles_label_hardcoded\", \"freezing_label\"]\n",
    "labels = RULE_BASED_LABELS+[\"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-level header\n",
    "df_pose_labels = pd.read_csv(DLC_DATASET_PATH + \"/labelled_DLC.csv\", header=[0, 1], index_col=0)\n",
    "\n",
    "# Flatten the multi-level header into single strings\n",
    "df_pose_labels.columns = ['_'.join(col).strip() for col in df_pose_labels.columns.values]\n",
    "\n",
    "# Remove second level header if it is empty\n",
    "df_pose_labels.columns = [col.split(\"_Unnamed\")[0] if \"_Unnamed\" in col else col for col in df_pose_labels.columns.values]\n",
    "\n",
    "# Remove NaN columns and rows\n",
    "df_pose_labels = df_pose_labels.dropna(axis=1, how='all')\n",
    "df_pose_labels = df_pose_labels.dropna(axis=0, how='any')\n",
    "\n",
    "print(\"Shape of df_pose_labels:\", df_pose_labels.shape)\n",
    "df_pose_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88487caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_pose_labels[RULE_BASED_LABELS]\n",
    "\n",
    "print(\"Shape of df_labels:\", df_labels.shape)\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643baa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all unlabeled are placed into \"other\"\n",
    "df_labels_other = df_labels.copy()\n",
    "df_labels_other[\"other\"] = 0\n",
    "\n",
    "# find all unlabeled\n",
    "unlabeled_data = df_labels_other.sum(axis=1) == 0\n",
    "\n",
    "# change all unlabeled to 1 in other\n",
    "df_labels_other.loc[unlabeled_data, \"other\"] = 1\n",
    "\n",
    "print(\"Shape of df_labels_other:\", df_labels_other.shape)\n",
    "df_labels_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124026b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pose = df_pose_labels.drop(columns=RULE_BASED_LABELS)\n",
    "\n",
    "print(\"Shape of df_pose:\", df_pose.shape)\n",
    "df_pose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pose_labels_other = pd.concat([df_pose, df_labels_other], axis=1)\n",
    "\n",
    "print(\"Shape of df_pose_labels_other:\", df_pose_labels_other.shape)\n",
    "df_pose_labels_other.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3291d5",
   "metadata": {},
   "source": [
    "## 2. Preprocessing using A-SOiD Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe0da3",
   "metadata": {},
   "source": [
    "### 2.1 Filter by Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12043c59",
   "metadata": {},
   "source": [
    "Smooths out unreliable keypoint coordinates based on confidence values (likelihoods). This is a \"hold last good value\" filter to avoid jittery or missing points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb75ffb",
   "metadata": {},
   "source": [
    "The `adp_filt` function is rewrite from the `adp_filt` function in A-SOiD (likelihood adaptive filtering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87635651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood adaptive filtering\n",
    "def adp_filt(df_pose_labels_other, idx_coord, idx_llh, llh_value, labels):\n",
    "    \"\"\"\n",
    "    For body parts with likelihood values below the threshold, copy the previous valid row's x, y coordinates.\n",
    "    Labels are not modified during filtering and are set back after filtering.\n",
    "\n",
    "    Parameters:\n",
    "        df_pose_labels_other (pd.DataFrame): The input DataFrame containing x, y, likelihood, and pose labels.\n",
    "        idx_coord (list): Indices of selected body parts (x and y columns).\n",
    "        idx_llh (list): Indices of likelihood columns.\n",
    "        llh_value (float): Threshold for likelihood filtering.\n",
    "        labels (list): List of pose labels to retain in the output.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with invalid x, y coordinates corrected.\n",
    "        dict: Statistics on filtered body parts and likelihood values below the threshold.\n",
    "    \"\"\"\n",
    "    # Convert DataFrame to numpy arrays for x, y, likelihood, and pose labels\n",
    "    data_x_coord = np.array(df_pose_labels_other.iloc[:, idx_coord[::2]])\n",
    "    data_y_coord = np.array(df_pose_labels_other.iloc[:, idx_coord[1::2]])\n",
    "    data_llh = np.array(df_pose_labels_other.iloc[:, idx_llh])\n",
    "    original_labels = df_pose_labels_other[labels].copy()  # Preserve original labels\n",
    "\n",
    "    # Initialize statistics\n",
    "    llh_below_threshold = 0\n",
    "    total_llh = data_llh.size  # Total number of likelihood values\n",
    "    body_part_stats = {df_pose_labels_other.columns[idx_coord[::2][i]]: 0 for i in range(len(idx_coord[::2]))}\n",
    "\n",
    "    # Iterate through body parts and correct invalid x, y coordinates\n",
    "    for x in range(data_llh.shape[1]):  # Iterate over each body part\n",
    "        for i in range(1, data_llh.shape[0]):  # Start from the second row\n",
    "            if data_llh[i, x] < llh_value:  # If likelihood is below the threshold\n",
    "                llh_below_threshold += 1\n",
    "                body_part_stats[df_pose_labels_other.columns[idx_coord[::2][x]]] += 1\n",
    "                # Copy the previous row's x, y coordinates for this body part\n",
    "                data_x_coord[i, x] = data_x_coord[i - 1, x]\n",
    "                data_y_coord[i, x] = data_y_coord[i - 1, x]\n",
    "\n",
    "    # Replace the x, y columns in the DataFrame with corrected values\n",
    "    for idx, col_idx in enumerate(idx_coord[::2]):  # Update x columns\n",
    "        df_pose_labels_other.iloc[:, col_idx] = data_x_coord[:, idx]\n",
    "    for idx, col_idx in enumerate(idx_coord[1::2]):  # Update y columns\n",
    "        df_pose_labels_other.iloc[:, col_idx] = data_y_coord[:, idx]\n",
    "\n",
    "    # Restore the original labels\n",
    "    df_pose_labels_other[labels] = original_labels\n",
    "\n",
    "    # Calculate likelihood ratio\n",
    "    llh_ratio = llh_below_threshold / total_llh\n",
    "\n",
    "    # Prepare statistics\n",
    "    stats = {\n",
    "        \"llh_below_threshold\": llh_below_threshold,\n",
    "        \"total_llh\": total_llh,\n",
    "        \"llh_below_threshold_ratio\": llh_ratio,\n",
    "        \"body_part_stats\": body_part_stats\n",
    "    }\n",
    "\n",
    "    return df_pose_labels_other, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f80d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric indices of columns ending with \"_likelihood\"\n",
    "idx_llh = [i for i, col in enumerate(df_pose_labels_other.columns) if col.endswith(\"_likelihood\")]\n",
    "labels = RULE_BASED_LABELS+[\"other\"]\n",
    "# Get numeric indices of columns of x and y coordinates\n",
    "idx_coord = [i for i, col in enumerate(df_pose_labels_other.columns) if not col.endswith(\"_likelihood\") and col not in labels]\n",
    "\n",
    "filt_df_pose_labels_other, stats = adp_filt(\n",
    "    df_pose_labels_other=df_pose_labels_other,\n",
    "    idx_coord=idx_coord,\n",
    "    idx_llh=idx_llh,\n",
    "    llh_value=LIKELIHOOD_THRESHOLD,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "print(\"Filtered DataFrame's shape:\")\n",
    "print(filt_df_pose_labels_other.shape)\n",
    "print(\"\\nStatistics:\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df_pose = filt_df_pose_labels_other.drop(columns=RULE_BASED_LABELS + [\"other\"])\n",
    "\n",
    "print(\"Filtered DataFrame's shape without labels:\")\n",
    "print(filt_df_pose.shape)\n",
    "filt_df_pose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df_labels_other = filt_df_pose_labels_other[RULE_BASED_LABELS + [\"other\"]]\n",
    "\n",
    "print(\"Filtered DataFrame's shape with labels:\")\n",
    "print(filt_df_labels_other.shape)\n",
    "filt_df_labels_other.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93709a15",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485170e",
   "metadata": {},
   "source": [
    "## 4. Rule-based Labeling (skipped for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb97991",
   "metadata": {},
   "source": [
    "## 5. Semi-supervised metric learning → low-dimensional vector embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadeaf6",
   "metadata": {},
   "source": [
    "## 6. Clustering (active learning loop skipped for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cf976",
   "metadata": {},
   "source": [
    "## 7. Train a decision tree classification model on engineered features to predict cluster IDs. This way we can get explainable feature importance (Explainability Model, interpretable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff16f3f",
   "metadata": {},
   "source": [
    "## 8. Train a classification model (maybe also decision tree) on embedded data to classify behaviors (Performance Model, accurate but abstract)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
